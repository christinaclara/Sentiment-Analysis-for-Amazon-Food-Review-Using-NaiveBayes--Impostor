{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyek PBA oleh Kelompok Impostor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis for Amazon Food Review Using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import csv\n",
    "import re\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn import metrics\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./Reviews.csv\",error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.Summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.Text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the unwanted columns from our data frame.\n",
    "dataset.drop(\"Id\", inplace=True, axis=1)\n",
    "dataset.drop(\"ProductId\", inplace=True, axis=1)\n",
    "dataset.drop(\"ProfileName\", inplace=True, axis=1)\n",
    "dataset.drop(\"HelpfulnessNumerator\", inplace=True, axis=1)\n",
    "dataset.drop(\"HelpfulnessDenominator\", inplace=True, axis=1)\n",
    "dataset.drop(\"Time\", inplace=True, axis=1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make all 'Score' less than 3 equal to -ve class and \n",
    "# 'Score' greater than 3 equal to +ve class.\n",
    "dataset.loc[dataset['Score']<3, 'Score'] = [0]\n",
    "dataset.loc[dataset['Score']>3, 'Score'] = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size=len(dataset)\n",
    "\n",
    "train_size=int(0.70*total_size)\n",
    "\n",
    "#untuk training dataset\n",
    "train=dataset.head(train_size)\n",
    "#untuk test dataset\n",
    "test=dataset.tail(total_size - train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menghapus semua baris dimana nilai sama dengan 3\n",
    "train = train[train.Score != 3]\n",
    "test = test[test.Score != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Score.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada tahap eksplorasi data akan dilakukan visualisasi review customer menggunakan Word Cloud. Word cloud (atau disebut juga tag cloud) adalah representasi visual dari data teks, biasanya digunakan untuk menggambarkan metadata atau untuk memvisualisasikan suatu bentuk teks secara bebas. Wordcloud (atau Tag cloud) adalah representasi visual dari data teks ini.  Ini menampilkan daftar kata dengan berbagai ukuran font atau warna yang berguna untuk memahami istilah yang paling menonjol dengan cepat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from wordcloud import STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merancang data frame \"review\" untuk ,menampilkan hasil eksplorasi data untuk dianalisis\n",
    "review = df\n",
    "# Menghilangkan nilai null\n",
    "review.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Membangun nilai (score) pada setiap review\n",
    "score_1 = review[review['Score'] == 1]\n",
    "score_2 = review[review['Score'] == 2]\n",
    "score_3 = review[review['Score'] == 3]\n",
    "score_4 = review[review['Score'] == 4]\n",
    "score_5 = review[review['Score'] == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampel = pd.concat([score_1,score_2,score_3,score_4,score_5],axis=0)\n",
    "sampel.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WordCloud membutuhkan inputan single string dari teks\n",
    "#Ringkasan review akan digabungkan menjadi single string\n",
    "# similarly akan dibangun melalui atribut Text\n",
    "review_str = sampel.Summary.str.cat()\n",
    "wordcloud = WordCloud(background_color='white').generate(reviews_str)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(wordcloud,interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split review yang bersifat buruk dengan score 1 dan 2 serta review baik dengan score 4 dan 5.\n",
    "bad_reviews = sampel[sampel['Score'].isin([1,2]) ]\n",
    "good_reviews = sampel[sampel['Score'].isin([4,5]) ]\n",
    "# Transform menjadi single string\n",
    "bad_reviews_str = bad_reviews.Summary.str.cat()\n",
    "good_reviews_str = good_reviews.Summary.str.cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_bad = WordCloud(background_color='white').generate(bad_reviews_str)\n",
    "wordcloud_good = WordCloud(background_color='black').generate(good_reviews_str)\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.imshow(wordcloud_negative,interpolation='bilinear')\n",
    "ax1.axis(\"off\")\n",
    "ax1.set_title('Review dengan Score Buruk',fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2.imshow(wordcloud_positive,interpolation='bilinear')\n",
    "ax2.axis(\"off\")\n",
    "ax2.set_title('Review dengan Score Baik',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis on Score (Target Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[dataset['Score'] != 3]\n",
    "dataset.shape \n",
    "#Checking to see how much % of data still remains\n",
    "print(f'Remaining data is {((dataset.shape[0]*1.0)/(dataset.shape[0]*1.0))*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = dataset['Score'].apply(lambda x: 1 if x > 3 else 0)\n",
    "dataset['Score'] = score\n",
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(df['Score'])\n",
    "plt.title('Target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis On ProductId and UserId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Reviews.csv\",error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will see the products brought by each customer\n",
    "\n",
    "purchases = df[['ProductId','UserId']].groupby('UserId').agg({'ProductId': ['count']})\n",
    "purchases.columns = ['No_of_products_purchased']\n",
    "purchases = purchases.reset_index()\n",
    "purchases.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "purchases['No_of_products_purchased'].hist()\n",
    "plt.xlabel('No of purchases')\n",
    "plt.ylabel('No of users')\n",
    "plt.show()\n",
    "print(purchases['No_of_products_purchased'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyisis of Reviews over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['Time'],unit='s')\n",
    "dff = df[['date','Text','Score']]\n",
    "dff.date = df.date.dt.strftime('%Y-%m')\n",
    "# dff['date'] = dff['date'].dt.to_timestamp()\n",
    "dff = dff.sort_values(by=['date']).reset_index(drop=True)\n",
    "dff_1 = dff[dff['Score'] == 1]\n",
    "dff_2 = dff[dff['Score'] == 2]\n",
    "dff_3 = dff[dff['Score'] == 3]\n",
    "dff_4 = dff[dff['Score'] == 4]\n",
    "dff_5 = dff[dff['Score'] == 5]\n",
    "\n",
    "dff_1 = dff_1.groupby('date')['Score'].count().reset_index()\n",
    "dff_2 = dff_2.groupby('date')['Score'].count().reset_index()\n",
    "dff_3 = dff_3.groupby('date')['Score'].count().reset_index()\n",
    "dff_5 = dff_4.groupby('date')['Score'].count().reset_index()\n",
    "dff_4 = dff_4.groupby('date')['Score'].count().reset_index()\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "plt.plot_date(x=dff_1['date'],y=dff_1['Score'],label='Score=1')\n",
    "plt.plot_date(x=dff_2['date'],y=dff_2['Score'],label='Score=2')\n",
    "plt.plot_date(x=dff_3['date'],y=dff_3['Score'],label='Score=3')\n",
    "plt.plot_date(x=dff_4['date'],y=dff_4['Score'],label='Score=4')\n",
    "plt.plot_date(x=dff_5['date'],y=dff_5['Score'],label='Score=5')\n",
    "plt.grid(linewidth=0.5,alpha=0.75)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlim('2000-01','2012-10')\n",
    "plt.xlabel('Date',fontsize=22)\n",
    "plt.ylabel('Number of review',fontsize=22)\n",
    "plt.title('Review trend from 2000 to 2012',fontsize=24);\n",
    "plt.savefig('review_trend.png')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Preprocessing akan menggunakan TextBlob Library. Dalam Text Preprocessing akan melakukan remove stop words, punctuations, convert into lower cases, lemmatize,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from textblob import TextBlob\n",
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower casing and removing punctuations\n",
    "df['Text'] = df['Text'].apply(lambda x: \" \".join(x.lower() for\n",
    "x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df['Text'].str.replace('[^\\w\\s]', \"\")\n",
    "df.Text.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the stopwords\n",
    "stop = stopwords.words('english')\n",
    "df['Text'] = df['Text'].apply(lambda x: \" \".join(x for x in\n",
    "x.split() if x not in stop))\n",
    "df.Text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatization\n",
    "df['Text'] = df['Text'].apply(lambda x: \" \".join([Word(word).\n",
    "lemmatize() for word in x.split()]))\n",
    "df.Text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
